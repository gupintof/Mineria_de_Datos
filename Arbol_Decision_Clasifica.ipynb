{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B2qmPbMvrNk"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# üìå Celda 1: Instalaci√≥n y carga de librer√≠as\n",
        "# ============================================================\n",
        "#!pip install scikit-learn matplotlib seaborn pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìå Celda 2: Importar librer√≠as\n",
        "# ============================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "OOESvrRTv1PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìå Celda 3: Cargar dataset (Wine Quality - Vino Tinto)\n",
        "# ============================================================\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
        "wine = pd.read_csv(url, sep=\";\")\n",
        "wine[\"quality\"].value_counts()\n",
        "\n"
      ],
      "metadata": {
        "id": "IzqWBS1cv3t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine.head()"
      ],
      "metadata": {
        "id": "QCAKj8cXyrGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos variable binaria: calidad buena (>=6) vs mala (<6)\n",
        "wine[\"quality_label\"] = (wine[\"quality\"] >= 6).astype(int)\n",
        "\n",
        "X = wine.drop(columns=[\"quality\", \"quality_label\"])\n",
        "y = wine[\"quality_label\"]"
      ],
      "metadata": {
        "id": "uNHlejTtyOZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimensiones de X:\", X.shape)\n",
        "print(\"Distribuci√≥n de clases:\\n\", y.value_counts(normalize=True))\n",
        "\n",
        "wine.head()"
      ],
      "metadata": {
        "id": "KJkJW8GSyL5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìå Celda 4: Dividir datos en entrenamiento y prueba\n",
        "# ============================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Tama√±o entrenamiento:\", X_train.shape)\n",
        "print(\"Tama√±o prueba:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "iMz53rmfv_tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìå Celda 5: √Årbol \"grande\" con Gini (sin poda)\n",
        "# ============================================================\n",
        "clf_big_gini = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "clf_big_gini.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = clf_big_gini.predict(X_train)\n",
        "y_test_pred = clf_big_gini.predict(X_test)\n",
        "\n",
        "print(\"üîπ √Årbol grande - Gini (sin poda)\")\n",
        "print(\"Accuracy Entrenamiento:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"Accuracy Prueba:\", accuracy_score(y_test, y_test_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "Wys1U7o8wDiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå Reporte de m√©tricas en el set de prueba\n",
        "print(\"\\nReporte en test:\\n\", classification_report(y_test, y_test_pred, target_names=[\"Mala\",\"Buena\"]))\n",
        "\n",
        "# üìå Matriz de confusi√≥n\n",
        "sns.heatmap(confusion_matrix(y_test, y_test_pred), annot=True, cmap=\"Blues\",\n",
        "            xticklabels=[\"Mala\",\"Buena\"], yticklabels=[\"Mala\",\"Buena\"])\n",
        "plt.xlabel(\"Predicci√≥n\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Matriz de confusi√≥n - √Årbol grande (Gini)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XlyN32ARzO1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå Visualizaci√≥n del √°rbol completo\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(clf_big_gini, filled=True, feature_names=X.columns, class_names=[\"Mala\",\"Buena\"], fontsize=8)\n",
        "plt.title(\"√Årbol grande (sin poda, criterio Gini)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "luZ4-F1L0dsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de interpretaci√≥n de un nodo del √°rbol:\n",
        "#\n",
        "# alcohol <= 10.525\n",
        "# üëâ La caracter√≠stica usada para dividir en este nodo es \"alcohol\".\n",
        "#    Si el valor de alcohol es <= 10.525, el caso va a la rama izquierda.\n",
        "#    Si es mayor a 10.525, el caso va a la rama derecha.\n",
        "#\n",
        "# gini = 0.498\n",
        "# üëâ Impureza Gini del nodo.\n",
        "#    El valor va de 0 (puro, todas las muestras de la misma clase) a 0.5 (mezcla m√°xima en binario).\n",
        "#    Aqu√≠ 0.498 indica que las clases est√°n casi balanceadas (mitad y mitad).\n",
        "#\n",
        "# samples = 1119\n",
        "# üëâ N√∫mero total de muestras (filas del dataset) que llegan a este nodo.\n",
        "#\n",
        "# value = [521.0, 598.0]\n",
        "# üëâ Distribuci√≥n de clases en este nodo:\n",
        "#    - 521 vinos son de la clase \"Mala\" (0).\n",
        "#    - 598 vinos son de la clase \"Buena\" (1).\n",
        "#\n",
        "# class = Buena\n",
        "# üëâ Clase mayoritaria en este nodo.\n",
        "#    Como 598 > 521, la predicci√≥n por defecto en este nodo ser√≠a \"Buena\".\n"
      ],
      "metadata": {
        "id": "Eda1zQ3b104t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìå Celda 6: Poda con max_depth\n",
        "# ============================================================\n",
        "clf_pruned = DecisionTreeClassifier(criterion=\"gini\", max_depth=5, random_state=42)\n",
        "clf_pruned.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred_pruned = clf_pruned.predict(X_train)\n",
        "y_test_pred_pruned = clf_pruned.predict(X_test)\n",
        "\n",
        "print(\"üîπ √Årbol podado - Gini (max_depth=5)\")\n",
        "print(\"Accuracy Entrenamiento:\", accuracy_score(y_train, y_train_pred_pruned))\n",
        "print(\"Accuracy Prueba:\", accuracy_score(y_test, y_test_pred_pruned))\n",
        "\n",
        "# üìå Visualizaci√≥n del √°rbol podado\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(clf_pruned, filled=True, feature_names=X.columns, class_names=[\"Mala\",\"Buena\"], fontsize=10)\n",
        "plt.title(\"√Årbol podado (max_depth=5, criterio Gini)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Dnl1oJAlwHDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìå Celda 7: Cambiar criterio a \"Entrop√≠a\"\n",
        "# ============================================================\n",
        "clf_entropy = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, random_state=42)\n",
        "clf_entropy.fit(X_train, y_train)\n",
        "\n",
        "y_pred_entropy = clf_entropy.predict(X_test)\n",
        "\n",
        "print(\"üîπ √Årbol podado - Entrop√≠a (max_depth=5)\")\n",
        "print(\"Accuracy en test:\", accuracy_score(y_test, y_pred_entropy))\n",
        "\n",
        "# üìå Visualizaci√≥n del √°rbol con entrop√≠a\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(clf_entropy, filled=True, feature_names=X.columns, class_names=[\"Mala\",\"Buena\"], fontsize=10)\n",
        "plt.title(\"√Årbol podado (max_depth=5, criterio Entrop√≠a)\")\n",
        "plt.show()\n",
        "\n",
        "# üìå Explicaci√≥n:\n",
        "# - El valor por defecto en DecisionTreeClassifier es \"gini\".\n",
        "# - Gini mide la probabilidad de clasificar mal un ejemplo si se elige aleatoriamente seg√∫n la distribuci√≥n de clases.\n",
        "# - Entrop√≠a mide la incertidumbre (teor√≠a de la informaci√≥n).\n",
        "# - Efectos:\n",
        "#   Gini ‚Üí m√°s r√°pido de calcular, favorece clases mayoritarias.\n",
        "#   Entrop√≠a ‚Üí puede equilibrar mejor divisiones si hay varias clases.\n",
        "# - En la pr√°ctica, la diferencia de rendimiento suele ser peque√±a.\n",
        "\n"
      ],
      "metadata": {
        "id": "sFrAa8olwNvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìå Celda 8: B√∫squeda sistem√°tica de hiperpar√°metros con GridSearchCV\n",
        "# ============================================================\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definimos los hiperpar√°metros a explorar\n",
        "param_grid = {\n",
        "    \"criterion\": [\"gini\", \"entropy\"],      # funci√≥n de impureza\n",
        "    \"max_depth\": [3, 5, 7, None],          # profundidad m√°xima\n",
        "    \"min_samples_split\": [2, 10, 20],      # m√≠nimo de muestras para dividir\n",
        "    \"min_samples_leaf\": [1, 5, 10],        # m√≠nimo de muestras por hoja\n",
        "    \"max_features\": [None, \"sqrt\", \"log2\"] # n√∫mero m√°ximo de variables a considerar en cada split\n",
        "}\n",
        "\n",
        "# Configuramos el GridSearch\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,                 # validaci√≥n cruzada 5-fold\n",
        "    scoring=\"accuracy\",   # m√©trica a optimizar\n",
        "    n_jobs=-1             # usa todos los cores disponibles\n",
        ")\n",
        "\n",
        "# Ajustamos el modelo\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Mejor modelo encontrado\n",
        "best_tree = grid_search.best_estimator_\n",
        "\n",
        "print(\"üîπ Mejor combinaci√≥n de hiperpar√°metros:\", grid_search.best_params_)\n",
        "print(\"üîπ Mejor accuracy en validaci√≥n cruzada:\", grid_search.best_score_)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0O1-lLLewT4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos en el set de test\n",
        "y_pred_best = best_tree.predict(X_test)\n",
        "\n",
        "print(\"\\nAccuracy en test:\", accuracy_score(y_test, y_pred_best))\n",
        "print(\"\\nReporte en test:\\n\", classification_report(y_test, y_pred_best, target_names=[\"Mala\",\"Buena\"]))\n",
        "\n",
        "# üìå Matriz de confusi√≥n\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_best), annot=True, cmap=\"Purples\",\n",
        "            xticklabels=[\"Mala\",\"Buena\"], yticklabels=[\"Mala\",\"Buena\"])\n",
        "plt.xlabel(\"Predicci√≥n\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Matriz de confusi√≥n - √Årbol optimizado con GridSearchCV\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "PtoRb0_B2F9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå Visualizaci√≥n del mejor √°rbol\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(best_tree, filled=True, feature_names=X.columns, class_names=[\"Mala\",\"Buena\"], fontsize=9)\n",
        "plt.title(\"√Årbol optimizado con GridSearchCV\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iW1MQgvK2ETG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìå Celda 9: Comparaci√≥n final de modelos\n",
        "# ============================================================\n",
        "acc_results = {\n",
        "    \"√Årbol grande (Gini)\": accuracy_score(y_test, y_test_pred),\n",
        "    \"√Årbol podado (Gini)\": accuracy_score(y_test, y_test_pred_pruned),\n",
        "    \"√Årbol podado (Entrop√≠a)\": accuracy_score(y_test, y_pred_entropy),\n",
        "    \"√Årbol optimizado (GridSearchCV)\": accuracy_score(y_test, y_pred_best),\n",
        "}\n",
        "\n",
        "for modelo, acc in acc_results.items():\n",
        "    print(f\"{modelo}: {acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_DZNdmbWwWbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìå Celda 10: Comparaci√≥n Train vs Test Accuracy\n",
        "# ============================================================\n",
        "\n",
        "# Accuracy en entrenamiento\n",
        "train_acc_results = {\n",
        "    \"√Årbol grande (Gini)\": accuracy_score(y_train, y_train_pred),\n",
        "    \"√Årbol podado (Gini)\": accuracy_score(y_train, y_train_pred_pruned),\n",
        "    \"√Årbol podado (Entrop√≠a)\": accuracy_score(y_train, clf_entropy.predict(X_train)),\n",
        "    \"√Årbol optimizado (GridSearchCV)\": accuracy_score(y_train, best_tree.predict(X_train)),\n",
        "}\n",
        "\n",
        "# Accuracy en prueba (ya calculado en Celda 9)\n",
        "test_acc_results = acc_results\n",
        "\n",
        "# Convertimos a DataFrame para graficar\n",
        "df_acc = pd.DataFrame({\n",
        "    \"Train\": train_acc_results,\n",
        "    \"Test\": test_acc_results\n",
        "}).T  # transponemos para que los modelos queden como filas\n",
        "\n",
        "# üìä Gr√°fico comparativo con etiquetas\n",
        "ax = df_acc.plot(kind=\"bar\", figsize=(10,6), rot=15, color=[\"skyblue\",\"salmon\"])\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Comparaci√≥n Accuracy en Train vs Test - √Årboles de Decisi√≥n\")\n",
        "plt.ylim(0,1)\n",
        "plt.legend(title=\"Conjunto\")\n",
        "\n",
        "# A√±adimos etiquetas num√©ricas encima de cada barra\n",
        "for p in ax.patches:\n",
        "    ax.annotate(\n",
        "        f\"{p.get_height():.2f}\",             # texto con 2 decimales\n",
        "        (p.get_x() + p.get_width() / 2, p.get_height()), # posici√≥n\n",
        "        ha=\"center\", va=\"bottom\", fontsize=9, color=\"black\", xytext=(0,3), textcoords=\"offset points\"\n",
        "    )\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "hQsFmNGIwZZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìå Conclusi√≥n\n",
        "\n",
        "Aunque el **√°rbol optimizado con GridSearchCV** muestra el **menor accuracy en el set de prueba**, es el modelo m√°s recomendable porque alcanza un mejor equilibrio entre **complejidad y capacidad de generalizaci√≥n**.  \n",
        "El **√°rbol grande con Gini** logra la mayor exactitud, pero lo hace a costa de un **sobreajuste evidente**: memoriza en exceso el conjunto de entrenamiento y pierde robustez ante datos nuevos.  \n",
        "\n",
        "En cambio, el **√°rbol optimizado** ha sido ajustado mediante **validaci√≥n cruzada**, lo que asegura que su desempe√±o no dependa de un √∫nico set de datos, sino que refleje un comportamiento m√°s **estable, consistente e interpretable**.  \n",
        "En aplicaciones reales, donde los datos futuros nunca son id√©nticos a los de entrenamiento, es preferible un modelo con un accuracy ligeramente menor, pero que sea mucho m√°s **confiable y generalizable**.\n"
      ],
      "metadata": {
        "id": "F04XESuY4jYb"
      }
    }
  ]
}