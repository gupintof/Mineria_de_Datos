{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#  Naive Bayes: Teor√≠a y Aplicaci√≥n Pr√°ctica\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# üåæ Clasificador Naive Bayes (Teor√≠a y Pr√°ctica)\n",
        "\n",
        "El **m√©todo Naive Bayes** es un clasificador probabil√≠stico basado en el **Teorema de Bayes**,\n",
        "que calcula la probabilidad de que una observaci√≥n pertenezca a una clase dada la evidencia de sus caracter√≠sticas.\n",
        "\n",
        "## üß† Teor√≠a B√°sica\n",
        "\n",
        "El teorema de Bayes establece que:\n",
        "\n",
        "P(C|X) = [ P(X|C) * P(C) ] / P(X)\n",
        "\n",
        "\n",
        "Donde:\n",
        "\n",
        "- **P(C | X)** ‚Üí Probabilidad de que el mensaje pertenezca a una clase *C* (por ejemplo, ‚Äúspam‚Äù) despu√©s de ver el texto *X*.  \n",
        "- **P(X | C)** ‚Üí Probabilidad de ver ese texto *X* si ya sabemos que es de la clase *C*.  \n",
        "- **P(C)** ‚Üí Probabilidad de que un mensaje sea de la clase *C* antes de leerlo.  \n",
        "- **P(X)** ‚Üí Probabilidad total de ver el texto *X* (es igual para todas las clases).\n",
        "\n",
        "\n",
        "El t√©rmino ‚Äú**Naive**‚Äù (ingenuo) se debe a que asume que **todas las caracter√≠sticas son independientes entre s√≠**,\n",
        "lo cual rara vez es cierto en la pr√°ctica, pero el modelo sigue funcionando sorprendentemente bien.\n",
        "\n",
        "## ‚öôÔ∏è Variantes Comunes\n",
        "- **GaussianNB**: para variables continuas (valores num√©ricos).\n",
        "- **MultinomialNB**: para conteos o frecuencias (por ejemplo, texto).\n",
        "- **BernoulliNB**: para variables binarias (palabras presentes o ausentes).\n",
        "\n",
        "## üéõÔ∏è Hiperpar√°metros importantes\n",
        "- **alpha**: suavizado de Laplace (evita que probabilidades con cero frecuencia anulen el modelo).\n",
        "  - Valores altos ‚Üí m√°s suavizado, menor influencia de palabras raras.\n",
        "  - Valores bajos ‚Üí menos suavizado, m√°s sensible a palabras poco frecuentes.\n",
        "- **fit_prior**: si se usa o no la probabilidad previa de las clases.\n",
        "\n",
        "En este ejemplo veremos c√≥mo afectan estos hiperpar√°metros al rendimiento del modelo.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "npxc2ZEmF2RW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6q3o4T6oFzd3"
      },
      "outputs": [],
      "source": [
        "# ================================================\n",
        "# üß™ Ejemplo Pr√°ctico: Clasificaci√≥n de Mensajes\n",
        "# ================================================\n",
        "\n",
        "#!pip install scikit-learn matplotlib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ===========================================================\n",
        "# üìö Dataset\n",
        "# ===========================================================\n",
        "\n",
        "mensajes = [\n",
        "    # SPAM\n",
        "    \"gana dinero r√°pido con este m√©todo\",\n",
        "    \"oferta exclusiva para ti\",\n",
        "    \"compra ahora y recibe un descuento\",\n",
        "    \"felicitaciones has sido seleccionado\",\n",
        "    \"obt√©n un pr√©stamo sin intereses\",\n",
        "    \"recibe dinero f√°cil y r√°pido\",\n",
        "    \"tu cuenta ha sido elegida para un premio\",\n",
        "    \"ganaste un viaje a la playa totalmente gratis\",\n",
        "    \"oferta limitada solo hoy\",\n",
        "    \"aprovecha esta promoci√≥n especial\",\n",
        "\n",
        "    # NO SPAM\n",
        "    \"reuni√≥n del departamento ma√±ana\",\n",
        "    \"recordatorio de cita m√©dica\",\n",
        "    \"tus notas del examen est√°n listas\",\n",
        "    \"la tarea debe entregarse hoy\",\n",
        "    \"nos vemos en la escuela\",\n",
        "    \"gracias por tu ayuda con el informe\",\n",
        "    \"revisemos el trabajo antes de entregarlo\",\n",
        "    \"hoy toca clase de matem√°ticas\",\n",
        "    \"feliz cumplea√±os te deseo lo mejor\",\n",
        "    \"confirma tu asistencia a la reuni√≥n\"\n",
        "]\n",
        "\n",
        "etiquetas = [\n",
        "    \"spam\", \"spam\", \"spam\", \"spam\", \"spam\",\n",
        "    \"spam\", \"spam\", \"spam\", \"spam\", \"spam\",\n",
        "    \"no_spam\", \"no_spam\", \"no_spam\", \"no_spam\", \"no_spam\",\n",
        "    \"no_spam\", \"no_spam\", \"no_spam\", \"no_spam\", \"no_spam\"\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úâÔ∏è Vectorizaci√≥n de texto\n",
        "\n",
        "Los algoritmos de aprendizaje autom√°tico no pueden trabajar directamente con palabras,\n",
        "ya que necesitan n√∫meros para hacer c√°lculos.  \n",
        "Por eso, usamos un **vectorizador**, que convierte cada mensaje en un conjunto de n√∫meros.\n",
        "\n",
        "- **`CountVectorizer()`** toma todos los mensajes y construye un ‚Äúdiccionario‚Äù con las palabras que aparecen.  \n",
        "- Luego, **`fit_transform(mensajes)`** crea una matriz donde:\n",
        "  - Cada **fila** representa un mensaje.\n",
        "  - Cada **columna** representa una palabra.\n",
        "  - El valor en cada posici√≥n indica **cu√°ntas veces aparece esa palabra** en el mensaje.\n",
        "\n",
        "As√≠, el texto se transforma en una forma num√©rica que el modelo Naive Bayes puede entender.\n"
      ],
      "metadata": {
        "id": "yLr60u4_HRRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizaci√≥n de texto\n",
        "vectorizador = CountVectorizer()\n",
        "X = vectorizador.fit_transform(mensajes)\n"
      ],
      "metadata": {
        "id": "QqHrFNvIHCKz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisi√≥n en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, etiquetas, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "7KFIpa4LHGrn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚öôÔ∏è Explorando el efecto de los hiperpar√°metros\n",
        "\n",
        "En esta parte probamos **distintas configuraciones del modelo Naive Bayes** para ver c√≥mo cambian los resultados.\n",
        "\n",
        "Los hiperpar√°metros que estamos ajustando son:\n",
        "\n",
        "- **`alpha`** ‚Üí controla el *suavizado de Laplace*.  \n",
        "  Sirve para evitar que una palabra con frecuencia cero arruine los c√°lculos del modelo.  \n",
        "  - Valores peque√±os ‚Üí el modelo se ajusta m√°s a los datos (menos general).  \n",
        "  - Valores grandes ‚Üí el modelo se suaviza m√°s (m√°s general).\n",
        "\n",
        "- **`fit_prior`** ‚Üí indica si el modelo debe usar o no las probabilidades previas de las clases.  \n",
        "  - `True`: considera cu√°ntos ejemplos hay de cada clase en el conjunto de entrenamiento.  \n",
        "  - `False`: trata ambas clases como si fueran igual de probables.\n",
        "\n",
        "El bucle `for` prueba varias combinaciones de estos dos par√°metros, entrena un modelo para cada una y guarda su **precisi√≥n** (exactitud) en una tabla.  \n",
        "As√≠ podemos comparar qu√© valores dan el mejor rendimiento.\n"
      ],
      "metadata": {
        "id": "i7gvMP6TH0gH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===========================================================\n",
        "# üîß Explorando el efecto de los hiperpar√°metros\n",
        "# ===========================================================\n",
        "\n",
        "resultados = []\n",
        "\n",
        "# Probaremos diferentes valores de alpha y fit_prior\n",
        "for alpha in [0.01, 0.1, 0.5, 1.0, 2.0, 5.0]:\n",
        "    for prior in [True, False]:\n",
        "        modelo = MultinomialNB(alpha=alpha, fit_prior=prior)\n",
        "        modelo.fit(X_train, y_train)\n",
        "        y_pred = modelo.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        resultados.append({\n",
        "            \"alpha\": alpha,\n",
        "            \"fit_prior\": prior,\n",
        "            \"accuracy\": acc\n",
        "        })\n",
        "\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "print(\"Resultados con diferentes hiperpar√°metros:\\n\")\n",
        "print(df_resultados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4bNOEyKG82G",
        "outputId": "483c6522-7056-475f-ab0c-a4f3959e2f5b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados con diferentes hiperpar√°metros:\n",
            "\n",
            "    alpha  fit_prior  accuracy\n",
            "0    0.01       True       0.8\n",
            "1    0.01      False       0.8\n",
            "2    0.10       True       0.8\n",
            "3    0.10      False       0.8\n",
            "4    0.50       True       0.8\n",
            "5    0.50      False       0.8\n",
            "6    1.00       True       0.8\n",
            "7    1.00      False       0.8\n",
            "8    2.00       True       0.8\n",
            "9    2.00      False       0.8\n",
            "10   5.00       True       0.8\n",
            "11   5.00      False       0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===========================================================\n",
        "# üèÅ Entrenamos el mejor modelo y mostramos detalles\n",
        "# ===========================================================\n",
        "mejor = df_resultados.sort_values(\"accuracy\", ascending=False).iloc[0]\n",
        "modelo_final = MultinomialNB(alpha=mejor.alpha, fit_prior=mejor.fit_prior)\n",
        "modelo_final.fit(X_train, y_train)\n",
        "y_pred_final = modelo_final.predict(X_test)\n",
        "\n",
        "print(\"\\nüîπ Mejor configuraci√≥n encontrada:\")\n",
        "print(mejor)\n",
        "print(\"\\nüîπ Reporte de clasificaci√≥n:\")\n",
        "print(classification_report(y_test, y_pred_final))\n",
        "\n",
        "# Ejemplo de predicci√≥n nueva\n",
        "nuevo_mensaje = [\"obt√©n un descuento especial hoy\"]\n",
        "nuevo_vec = vectorizador.transform(nuevo_mensaje)\n",
        "print(\"üîπ Predicci√≥n para mensaje nuevo:\", modelo_final.predict(nuevo_vec)[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zZ18x8RBG2FG",
        "outputId": "619f33c0-83f6-4a3d-ee20-531c0a1aa85a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Mejor configuraci√≥n encontrada:\n",
            "alpha        0.01\n",
            "fit_prior    True\n",
            "accuracy      0.8\n",
            "Name: 0, dtype: object\n",
            "\n",
            "üîπ Reporte de clasificaci√≥n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     no_spam       0.67      1.00      0.80         2\n",
            "        spam       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.83      0.83      0.80         5\n",
            "weighted avg       0.87      0.80      0.80         5\n",
            "\n",
            "üîπ Predicci√≥n para mensaje nuevo: spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßÆ Ejemplo 2: Clasificaci√≥n con Gaussian Naive Bayes\n",
        "\n",
        "En este ejemplo usaremos el modelo **GaussianNB**, que se aplica a variables **num√©ricas continuas**.  \n",
        "A diferencia de *MultinomialNB* (que trabaja con texto y conteos de palabras),  \n",
        "este modelo asume que los datos siguen una **distribuci√≥n normal (gaussiana)** dentro de cada clase.\n",
        "\n",
        "Vamos a crear un conjunto peque√±o con dos caracter√≠sticas:\n",
        "- **Altura (cm)**\n",
        "- **Peso (kg)**\n",
        "\n",
        "El objetivo ser√° clasificar a cada persona en uno de dos grupos (`A` o `B`) seg√∫n sus medidas.\n",
        "\n",
        "---\n",
        "\n",
        "### üåæ ¬øQu√© hace el m√©todo Naive Bayes aqu√≠?\n",
        "\n",
        "El clasificador **Naive Bayes** usa el **Teorema de Bayes** para calcular la probabilidad de que un caso pertenezca a una clase.\n",
        "\n",
        "\\[\n",
        "P(C|X) = \\frac{P(X|C) \\times P(C)}{P(X)}\n",
        "\\]\n",
        "\n",
        "Donde:\n",
        "- **P(C|X)** ‚Üí probabilidad *a posteriori*: qu√© tan probable es que el ejemplo pertenezca a la clase *C* despu√©s de ver los datos *X*.  \n",
        "- **P(X|C)** ‚Üí probabilidad de observar esos valores si ya sabemos que es de la clase *C*.  \n",
        "- **P(C)** ‚Üí probabilidad *a priori* de la clase *C* (qu√© tan frecuente es).  \n",
        "- **P(X)** ‚Üí probabilidad total de observar los valores de *X* (igual para todas las clases).\n",
        "\n",
        "---\n",
        "\n",
        "### üß† ¬øPor qu√© ‚ÄúNaive‚Äù (ingenuo)?\n",
        "\n",
        "Porque el modelo **supone que las variables son independientes entre s√≠**.  \n",
        "En nuestro ejemplo, eso significa asumir que la *altura* y el *peso* no dependen una de la otra,  \n",
        "aunque en la realidad est√°n algo relacionadas.  \n",
        "Aun as√≠, esta simplificaci√≥n suele dar **muy buenos resultados**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚öôÔ∏è ¬øQu√© hace GaussianNB exactamente?\n",
        "\n",
        "1. Calcula la **media (Œº)** y la **desviaci√≥n est√°ndar (œÉ)** de cada variable dentro de cada grupo.  \n",
        "2. Usa la **f√≥rmula de la distribuci√≥n normal** para estimar la probabilidad de ver un valor dado.  \n",
        "3. Combina esas probabilidades para obtener la probabilidad total de que un individuo pertenezca a cada clase.  \n",
        "4. Elige la clase con la probabilidad *a posteriori* m√°s alta.\n",
        "\n",
        "---\n",
        "\n",
        "### üìà Intuici√≥n simple\n",
        "\n",
        "- Si alguien tiene **altura y peso cercanos** a los promedios del grupo B, el modelo lo clasificar√° como **B**.  \n",
        "- Si sus valores est√°n m√°s cerca de los del grupo A, lo asignar√° a **A**.  \n",
        "- Todo esto se hace usando **probabilidades**, no comparaciones directas.\n",
        "\n",
        "---\n",
        "\n",
        "En resumen, **Gaussian Naive Bayes** usa el teorema de Bayes con la suposici√≥n de que los datos num√©ricos de cada clase siguen una curva normal.  \n",
        "Es r√°pido, sencillo y funciona muy bien cuando los datos se distribuyen de forma m√°s o menos ‚Äúredondeada‚Äù alrededor de sus promedios.\n"
      ],
      "metadata": {
        "id": "ZSKyS1t7NXEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# üìä Ejemplo con datos num√©ricos ‚Äî GaussianNB\n",
        "# ===========================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n"
      ],
      "metadata": {
        "id": "xpBDNj7oMg36"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset peque√±o y equilibrado\n",
        "datos = pd.DataFrame({\n",
        "    \"altura\": [160, 165, 170, 155, 180, 175, 185, 150, 172, 168],\n",
        "    \"peso\":   [60, 65, 68, 50, 80, 75, 85, 48, 70, 66],\n",
        "    \"grupo\":  [\"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"A\", \"B\", \"B\"]\n",
        "})\n",
        "\n",
        "print(\"üìã Dataset inicial:\")\n",
        "print(datos)\n",
        "\n",
        "# Variables (X) y etiquetas (y)\n",
        "X = datos[[\"altura\", \"peso\"]]\n",
        "y = datos[\"grupo\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZb7jrVOMvSJ",
        "outputId": "6d74b79d-6f84-4091-e6e4-8ef8b0989dbb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Dataset inicial:\n",
            "   altura  peso grupo\n",
            "0     160    60     A\n",
            "1     165    65     A\n",
            "2     170    68     A\n",
            "3     155    50     A\n",
            "4     180    80     B\n",
            "5     175    75     B\n",
            "6     185    85     B\n",
            "7     150    48     A\n",
            "8     172    70     B\n",
            "9     168    66     B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividimos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "ih8W0V5zMs24"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# üß† Entrenamiento con GaussianNB\n",
        "# ===========================================================\n",
        "modelo = GaussianNB()\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "# Resultados\n",
        "print(\"\\nüîπ Precisi√≥n del modelo:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nüîπ Reporte de clasificaci√≥n:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYnJ3osVMomx",
        "outputId": "e6bf3f62-3f8d-46e1-8c6b-188dccb8733c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Precisi√≥n del modelo: 1.0\n",
            "\n",
            "üîπ Reporte de clasificaci√≥n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00         1\n",
            "           B       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo nuevo\n",
        "nuevo = [[178, 77]]  # Altura 178 cm, peso 77 kg\n",
        "prediccion = modelo.predict(nuevo)[0]\n",
        "print(f\"\\nüîπ Predicci√≥n para altura=178, peso=77 ‚Üí Grupo {prediccion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4TgnN3nMl5s",
        "outputId": "0227d324-9677-4da4-864d-75a689fec1a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Predicci√≥n para altura=178, peso=77 ‚Üí Grupo B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}